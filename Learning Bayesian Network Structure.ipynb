{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h1><center>Learning Bayesian Network Structure</center></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code contains class/function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import maxsize\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import copy\n",
    "import itertools\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#=====================================================================================================\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, name, configurations=['1','0'], thetas={'':[0.5,0.5]}):\n",
    "        self.name=name\n",
    "        self.configurations=configurations\n",
    "        self.thetas=thetas\n",
    "\n",
    "    def generate_sample(self,parents_config=''):\n",
    "        r=random.uniform(0,1)\n",
    "        threshold=0\n",
    "        count=0\n",
    "        for theta in self.thetas[parents_config]:\n",
    "            threshold+=theta\n",
    "            if r<threshold:\n",
    "                return self.configurations[count]\n",
    "            count+=1            \n",
    "\n",
    "#________________________________________________________________________________________________________\n",
    "\n",
    "class DAG:\n",
    "    def __init__(self,nodes,randomInit=False):\n",
    "        self.size=len(nodes)\n",
    "        self.nodes=nodes\n",
    "        self.adj_mat=np.zeros((self.size,self.size),dtype=int)\n",
    "        if randomInit:\n",
    "            for i in range(self.size):\n",
    "                for j in range(self.size):\n",
    "                    if random.randint(0,1):\n",
    "                        self.add_edge((i,j))   \n",
    "    def get_parents(self,node):\n",
    "        return np.where(self.adj_mat[:,node]==1)[0]\n",
    "    def get_successors(self,node):\n",
    "        return np.where(self.adj_mat[node,:]==1)[0]\n",
    "    def add_edge(self,edge):\n",
    "        u=edge[0]\n",
    "        v=edge[1]\n",
    "        if self.adj_mat[u,v]==1 or self.adj_mat[v,u]==1 or u==v or self.path_exists((v,u)):\n",
    "            return False\n",
    "        self.adj_mat[u,v]=1\n",
    "        return True\n",
    "    def remove_edge(self,edge):\n",
    "        u=edge[0]\n",
    "        v=edge[1]\n",
    "        if self.adj_mat[u,v]==0 or u==v:\n",
    "            return False\n",
    "        self.adj_mat[u,v]=0\n",
    "        return True\n",
    "    def invert_edge(self,edge):\n",
    "        u=edge[0]\n",
    "        v=edge[1]\n",
    "        if self.adj_mat[u,v]==0 or u==v:\n",
    "            return False\n",
    "        self.adj_mat[u,v]=0\n",
    "        if self.path_exists((u,v)):\n",
    "            self.adj_mat[u,v]=1\n",
    "            return False\n",
    "        self.adj_mat[v,u]=1        \n",
    "        return True\n",
    "    def path_exists(self,edge):\n",
    "        u=edge[0]\n",
    "        v=edge[1]\n",
    "        explored=set()\n",
    "        frontier=[]\n",
    "        frontier.append(u)\n",
    "        while frontier:\n",
    "            node=frontier.pop()\n",
    "            if node==v:\n",
    "                return True\n",
    "            if node not in explored and node not in frontier:\n",
    "                explored.add(node)\n",
    "                for neighbor in self.get_successors(node):\n",
    "                    frontier.append(neighbor)\n",
    "        return False\n",
    "    def topological_sort(self):\n",
    "        explored=set()\n",
    "        result = []\n",
    "        def recursive_helper(node,result):\n",
    "            for neighbor in self.get_successors(node):\n",
    "                if neighbor not in explored:\n",
    "                    explored.add(neighbor)\n",
    "                    recursive_helper(neighbor,result)\n",
    "            result.insert(0,node)\n",
    "        for node in range(self.size):\n",
    "            if(node not in explored):\n",
    "                recursive_helper(node,result)\n",
    "        return result\n",
    "    def generate_sample(self):\n",
    "        order = self.topological_sort()\n",
    "        sample = np.zeros(self.size,dtype=str)\n",
    "        for node in order:\n",
    "            #get parent's configuration\n",
    "            parents_config = ''\n",
    "            for parent in self.get_parents(node):\n",
    "                parents_config += str(sample[parent])\n",
    "            #generate sample\n",
    "            sample[node] = self.nodes[node].generate_sample(parents_config)\n",
    "        return sample\n",
    "    def print(self):\n",
    "        print(self.adj_mat)\n",
    "    def draw(self,message='graph plot'):\n",
    "        G = nx.from_numpy_array(self.adj_mat,create_using=nx.DiGraph)\n",
    "        G = nx.relabel_nodes(G,{i:name for (i,name) in zip(range(self.size),[node.name for node in self.nodes])})\n",
    "        posG = nx.circular_layout(G)\n",
    "        plt.figure(message)\n",
    "        nx.draw_networkx(G, pos=posG, node_color='#B0DBFF')\n",
    "        plt.draw()\n",
    "        plt.show()\n",
    "\n",
    "#=====================================================================================================\n",
    "\n",
    "def node_score(graph, node, count):\n",
    "    score = 0\n",
    "\n",
    "    num_configs_parents = np.sum([len(graph.nodes[parent].configurations) for parent in  graph.get_parents(node)])\n",
    "    if num_configs_parents == 0:\n",
    "        num_configs_parents = 1\n",
    "    denominator = num_configs_parents * len(graph.nodes[node].configurations)\n",
    "\n",
    "    if len(graph.get_parents(node)) != 0:\n",
    "        for parents_config in itertools.product(\n",
    "                *[graph.nodes[parent].configurations for parent in graph.get_parents(node)]):\n",
    "            n_ij = 0\n",
    "            alpha_ij = 0\n",
    "            for node_config in graph.nodes[node].configurations:\n",
    "                ijk = str(node) + ',' + ''.join(parents_config) + ',' + node_config\n",
    "                if ijk in count:\n",
    "                    n_ijk = count[ijk]\n",
    "                else:\n",
    "                    n_ijk = 0\n",
    "\n",
    "                # equivalent sample size = 1\n",
    "                alpha_ijk = 1/denominator\n",
    "\n",
    "                score += math.lgamma(alpha_ijk + n_ijk) - math.lgamma(alpha_ijk)\n",
    "                n_ij += n_ijk\n",
    "                alpha_ij += alpha_ijk\n",
    "            score += math.lgamma(alpha_ij) - math.lgamma(alpha_ij + n_ij)\n",
    "    else:\n",
    "        n_ij = 0\n",
    "        alpha_ij = 0\n",
    "        for node_config in graph.nodes[node].configurations:\n",
    "            if str(node) + ',,' + node_config in count:\n",
    "                n_ijk = count[str(node) + ',,' + node_config]\n",
    "            else:\n",
    "                n_ijk = 0\n",
    "\n",
    "            # equivalent sample size = 1\n",
    "            alpha_ijk = 1/denominator\n",
    "\n",
    "            score += math.lgamma(alpha_ijk + n_ijk) - math.lgamma(alpha_ijk)\n",
    "            n_ij += n_ijk\n",
    "            alpha_ij += alpha_ijk\n",
    "        score += math.lgamma(alpha_ij) - math.lgamma(alpha_ij + n_ij)\n",
    "    return score\n",
    "\n",
    "#________________________________________________________________________________________________________\n",
    "\n",
    "def accuracy(referenceDag, testingDag):\n",
    "    #True Positives + True Negatives: 'presence of edges with same orientation' + 'absence of edges'\n",
    "    adj_R = referenceDag.adj_mat\n",
    "    adj_T = testingDag.adj_mat\n",
    "    size = referenceDag.size\n",
    "    \n",
    "    correct = 0   #TP + TN\n",
    "    wrong = 0     #FP + FN \n",
    "    for i in range(size):\n",
    "        for j in range(i,size):\n",
    "            if adj_R[i][j] == adj_T[i][j]:\n",
    "                correct += 1\n",
    "            else:\n",
    "                wrong += 1\n",
    "    \n",
    "    return correct/(correct+wrong)\n",
    "\n",
    "#________________________________________________________________________________________________________\n",
    "\n",
    "def beam_search(b, nodes, dataset, suppressOutput=False):\n",
    "    graphs = [DAG(nodes, True) for i in range(b)]\n",
    "    counts = [{} for i in range(b)]\n",
    "    scores = [0 for i in range(b)]\n",
    "\n",
    "    # calculate counts and score for initial graphs\n",
    "    for graph, count, index in zip(graphs, counts, range(b)):\n",
    "\n",
    "        for example in dataset:\n",
    "            for node in range(graph.size):\n",
    "                ijk = str(node) + ','  # i\n",
    "                for parent in graph.get_parents(node):\n",
    "                    ijk += str(example[parent])  # j\n",
    "                ijk += ',' + str(example[node])  # k\n",
    "                if ijk in count:\n",
    "                    count[ijk] += 1\n",
    "                else:\n",
    "                    count[ijk] = 1\n",
    "        for node in range(graph.size):\n",
    "            scores[index] += node_score(graph, node, count)\n",
    "    \n",
    "    iter = 0\n",
    "    best_score = -maxsize\n",
    "    while True:\n",
    "        new_graphs = copy.deepcopy(graphs)\n",
    "        new_counts = copy.deepcopy(counts)\n",
    "        new_scores = copy.deepcopy(scores)\n",
    "\n",
    "        #TESTING\n",
    "        #counter=0\n",
    "\n",
    "        for graph, count, score in zip(graphs, counts, scores):\n",
    "            #TESTING\n",
    "            #print('\\n\\nDISCOVERING FROM GRAPH #'+str(counter))\n",
    "            #counter+=1\n",
    "            #graph.draw()\n",
    "            #print(graph.adj_mat)\n",
    "            #print('^score:' + str(score))\n",
    "\n",
    "            for i in range(graph.size):\n",
    "                for j in range(graph.size):\n",
    "\n",
    "                    # try adding an edge\n",
    "                    if graph.add_edge((i, j)):\n",
    "                        #TESTING\n",
    "                        #print('\\nadding edge: (' + str(i) + ','+str(j)+')')\n",
    "                        new_graphs.append(copy.deepcopy(graph))\n",
    "                        new_graph = new_graphs[-1]\n",
    "                        new_counts.append(copy.deepcopy(count))\n",
    "                        new_count = new_counts[-1]\n",
    "\n",
    "                        graph.remove_edge((i, j))\n",
    "\n",
    "                        # update new_count\n",
    "                        for j_config in graph.nodes[j].configurations:\n",
    "                            key = str(j) + ','\n",
    "                            for parents_config in itertools.product(\n",
    "                                    *[graph.nodes[parent].configurations for parent in graph.get_parents(j)]):\n",
    "                                key = str(node) + ',' + ''.join(parents_config) + ',' + str(j_config)\n",
    "                                if key in new_count:\n",
    "                                    del new_count[key]\n",
    "\n",
    "                        for example in dataset:\n",
    "                            ijk = str(j) + ','  # i\n",
    "                            for parent in new_graph.get_parents(j):\n",
    "                                ijk += str(example[parent])  # j\n",
    "                            ijk += ',' + str(example[j])  # k\n",
    "                            if ijk in new_count:\n",
    "                                new_count[ijk] += 1\n",
    "                            else:\n",
    "                                new_count[ijk] = 1\n",
    "\n",
    "                        # update new_score\n",
    "                        old_node_score = node_score(graph, j, count)\n",
    "                        new_node_score = node_score(new_graph, j, new_count)\n",
    "                        new_scores.append(score - old_node_score + new_node_score)\n",
    "\n",
    "                        #TESTING\n",
    "                        #new_graph.draw()\n",
    "                        #print(new_graph.adj_mat)\n",
    "                        #print('^score:' + str(score - old_node_score + new_node_score))\n",
    "\n",
    "                    # try removing an edge\n",
    "                    if graph.remove_edge((i, j)):\n",
    "                        #TESTING\n",
    "                        #print('\\nremoving edge: (' + str(i) + ','+str(j)+')')\n",
    "                        new_graphs.append(copy.deepcopy(graph))\n",
    "                        new_counts.append(copy.deepcopy(count))\n",
    "                        new_graph = new_graphs[-1]\n",
    "                        new_count = new_counts[-1]\n",
    "\n",
    "                        graph.add_edge((i, j))\n",
    "\n",
    "                        # update new_count\n",
    "                        for j_config in graph.nodes[j].configurations:\n",
    "                            key = str(j) + ','\n",
    "                            for parents_config in itertools.product(\n",
    "                                    *[graph.nodes[parent].configurations for parent in graph.get_parents(j)]):\n",
    "                                key = str(node) + ',' + ''.join(parents_config) + ',' + str(j_config)\n",
    "                                if key in new_count:\n",
    "                                    del new_count[key]\n",
    "\n",
    "                        for example in dataset:\n",
    "                            ijk = str(j) + ','  # i\n",
    "                            for parent in new_graph.get_parents(j):\n",
    "                                ijk += str(example[parent])  # j\n",
    "                            ijk += ',' + str(example[j])  # k\n",
    "                            if ijk in new_count:\n",
    "                                new_count[ijk] += 1\n",
    "                            else:\n",
    "                                new_count[ijk] = 1\n",
    "\n",
    "                        # update new_score\n",
    "                        old_node_score = node_score(graph, j, count)\n",
    "                        new_node_score = node_score(new_graph, j, new_count)\n",
    "                        new_scores.append(score - old_node_score + new_node_score)\n",
    "\n",
    "                        #TESTING\n",
    "                        #new_graph.draw()\n",
    "                        #print(new_graph.adj_mat)\n",
    "                        #print('^score:' + str(score - old_node_score + new_node_score))\n",
    "                    \n",
    "                    # try inverting an edge \n",
    "                    if graph.invert_edge((i, j)):\n",
    "                        #TESTING\n",
    "                        #print('\\ninverting edge: (' + str(i) + ','+str(j)+')')\n",
    "                        new_graphs.append(copy.deepcopy(graph))\n",
    "                        new_counts.append(copy.deepcopy(count))\n",
    "                        new_graph = new_graphs[-1]\n",
    "                        new_count = new_counts[-1]\n",
    "\n",
    "                        graph.invert_edge((j, i))\n",
    "\n",
    "                        # update new_count\n",
    "                        for node in [i, j]:\n",
    "                            for node_config in graph.nodes[node].configurations:\n",
    "                                key = str(node) + ','\n",
    "                                for parents_config in itertools.product(\n",
    "                                        *[graph.nodes[parent].configurations for parent in graph.get_parents(node)]):\n",
    "                                    key = str(node) + ',' + ''.join(parents_config) + ',' + str(node_config)\n",
    "                                    if key in new_count:\n",
    "                                        del new_count[key]\n",
    "\n",
    "                            for example in dataset:\n",
    "                                ijk = str(node) + ','  # i\n",
    "                                for parent in new_graph.get_parents(node):\n",
    "                                    ijk += str(example[parent])  # j\n",
    "                                ijk += ',' + str(example[node])  # k\n",
    "                                if ijk in new_count:\n",
    "                                    new_count[ijk] += 1\n",
    "                                else:\n",
    "                                    new_count[ijk] = 1\n",
    "\n",
    "                        # update new_score\n",
    "                        old_node_i_score = node_score(graph, i, count)\n",
    "                        old_node_j_score = node_score(graph, j, count)\n",
    "                        new_node_i_score = node_score(new_graph, i, new_count)\n",
    "                        new_node_j_score = node_score(new_graph, j, new_count)\n",
    "                        new_scores.append(score - old_node_i_score - old_node_j_score + new_node_i_score + new_node_j_score)\n",
    "\n",
    "                        #TESTING\n",
    "                        #new_graph.draw()\n",
    "                        #print(new_graph.adj_mat)\n",
    "                        #print('^score:' + str(score - old_node_i_score - old_node_j_score + new_node_i_score + new_node_j_score))\n",
    "\n",
    "        # save b best scoring graphs\n",
    "        order = np.argpartition(np.array(new_scores), -b)[-b:]\n",
    "        graphs = [new_graphs[i] for i in order]\n",
    "        counts = [new_counts[i] for i in order]\n",
    "        scores = [new_scores[i] for i in order]\n",
    "\n",
    "        # is there any progress?\n",
    "        #print('\\nchecking for progress...')\n",
    "        if max(scores) > best_score:\n",
    "            best_score = max(scores)\n",
    "            if suppressOutput == False:\n",
    "                print(\"\\nGeneration \" + str(iter) + ':\\nbest score: ' + str(best_score))\n",
    "                print('new generation has ' + str(len(new_graphs)) + ' DAGs, of which ' + str(b) + ' will survive.')\n",
    "                graphs[0].draw()\n",
    "            iter += 1\n",
    "        else:\n",
    "            if suppressOutput == False:\n",
    "                print('\\nno progress... ending...')\n",
    "            break\n",
    "\n",
    "    return graphs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution\n",
    "By running the corresponding block, select the Bayesian Network you wish to learn the structure of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dag1 = DAG([\n",
    "    Node(\"0\",['1','0'],{'':[0.01, 0.99]}),                                                      #asia\n",
    "    Node(\"1\",['1','0'],{'1':[0.05, 0.95], '0':[ 0.01, 0.99]}),                                  #tub\n",
    "    Node(\"2\",['1','0'],{'':[0.5, 0.5]}),                                                        #smoke\n",
    "    Node(\"3\",['1','0'],{'1':[ 0.1, 0.9], '0':[0.01, 0.99]}),                                    #lung\n",
    "    Node(\"4\",['1','0'],{'1':[0.6, 0.4], '0':[0.3, 0.7]}),                                       #bronc\n",
    "    Node(\"5\",['1','0'],{'11':[1.0, 0.0], '01':[1.0, 0.0], '10':[1.0, 0.0], '00':[0.0, 1.0]}),   #either\n",
    "    Node(\"6\",['1','0'],{'1':[0.98, 0.02], '0':[0.05, 0.95]}),                                   #xray\n",
    "    Node(\"7\",['1','0'],{'11': [0.9, 0.1], '01':[ 0.7, 0.3], '10':[0.8, 0.2],'00':[0.1, 0.9]})]) #dysp\n",
    "\n",
    "my_dag1.add_edge((0,1))\n",
    "my_dag1.add_edge((1,5))\n",
    "my_dag1.add_edge((2,3))\n",
    "my_dag1.add_edge((2,4))\n",
    "my_dag1.add_edge((3,5))\n",
    "my_dag1.add_edge((4,7))\n",
    "my_dag1.add_edge((5,6))\n",
    "my_dag1.add_edge((5,7))\n",
    "\n",
    "my_dag=my_dag1\n",
    "my_dag.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dag2 = DAG([\n",
    "    Node(\"0\",['l','h'],{'':[0.9, 0.1]}),                                                                #Pollution\n",
    "    Node(\"1\",['1','0'],{'':[0.3, 0.7]}),                                                                #Smoker\n",
    "    Node(\"2\",['1','0'],{'l1':[0.03, 0.97],'h1':[0.05, 0.95],'l0':[0.001, 0.999],'h0':[0.02, 0.98]}),    #Cancer\n",
    "    Node(\"3\",['+','-'],{'1':[0.9, 0.1], '0':[0.2, 0.8]}),                                               #Xray\n",
    "    Node(\"4\",['1','0'],{'1':[0.65, 0.35], '0':[0.3, 0.7]})])                                            #Dyspnoea\n",
    "\n",
    "my_dag2.add_edge((0,2))\n",
    "my_dag2.add_edge((1,2))\n",
    "my_dag2.add_edge((2,3))\n",
    "my_dag2.add_edge((2,4))\n",
    "\n",
    "my_dag=my_dag2\n",
    "my_dag.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dag3 = DAG([\n",
    "    Node(\"0\",['1','0'],{'':[0.9, 0.1]}),                   #A  \n",
    "    Node(\"1\",['1','0'],{'1':[0.3, 0.7],'0':[0.1,0.9]}),    #B \n",
    "    Node(\"2\",['1','0'],{'1':[0.2,0.8],'0':[0.4,0.6]})])    #C\n",
    "\n",
    "my_dag3.add_edge((0,1))\n",
    "my_dag3.add_edge((1,2))\n",
    "\n",
    "my_dag=my_dag3\n",
    "my_dag.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the number of examples you would like in the dataset (n), and the size of the beam (b) for the Beam Search algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=2500 #number of examples\n",
    "b=10   #size of beam\n",
    "\n",
    "print(\"Generating dataset with \" + str(n) +\" entries...\\n\")\n",
    "dataset=np.zeros((n,my_dag.size),dtype=str)\n",
    "for i in range(n):\n",
    "    dataset[i,:] = my_dag.generate_sample()\n",
    "    \n",
    "print(dataset)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy measures the fraction of identical (also in direction) edges (TP) plus the fraction of edges missing in both (TN) over all the possible edges (TP+TN+FP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Chose to learn structure of:\")\n",
    "my_dag.draw()\n",
    "\n",
    "print(\"Running beam_search with beam size b=\"+str(b)+'...\\n')\n",
    "result=beam_search(b, my_dag.nodes,dataset)\n",
    "\n",
    "print('Final Belief Network:')\n",
    "result.draw()    \n",
    "\n",
    "print('\\naccuracy: ' + str(accuracy(my_dag,result)*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to observe how the accuracy scales for larger and larger datasets (on learning the selected graph), use the following code to specify the number of tests (num_tests) to perform (each one num_redundancy_tests times, in order to smooth out the result) up to a maximum dataset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_tests = 10 \n",
    "num_redundancy_tests = 20\n",
    "max_dataset_n = 5000\n",
    "\n",
    "dataset_sizes_n = [int(n * max_dataset_n/num_tests) for n in range(1,num_tests+1)]\n",
    "accuracies = np.zeros(num_tests)\n",
    "for count in range(num_tests):\n",
    "    n = int(count * max_dataset_n/num_tests) \n",
    "    redundant_accuracies = np.zeros(num_redundancy_tests)\n",
    "    for i in range(num_redundancy_tests):\n",
    "        dataset=np.zeros((n, my_dag.size),dtype=str)\n",
    "        for j in range(n):\n",
    "            dataset[j,:] = my_dag.generate_sample()\n",
    "        redundant_accuracies[i] = accuracy(my_dag, beam_search(b, my_dag.nodes,dataset,True))\n",
    "        print('\\r', 'testing progress: ' + str(100*(count*num_redundancy_tests + i + 1)/(num_tests*num_redundancy_tests)) + '%                   ', end='')\n",
    "    accuracies[count] = np.mean(redundant_accuracies)\n",
    "    \n",
    "plt.plot(dataset_sizes_n, accuracies)\n",
    "plt.title('learning accuracy')\n",
    "plt.xlabel('size of dataset (n)')\n",
    "plt.ylabel('accuracy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
